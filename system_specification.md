# System Specification Document

**Project**: Insect Detection Training Project  
**Version**: 1.0  
**Date**: 2025-07-03  
**Author**: Development Team  

---

## 1. Executive Summary

This document provides a comprehensive technical specification for the Insect Detection Training Project, a YOLOv8-based machine learning system designed to train custom models for beetle detection. The system encompasses model training, validation, and deployment workflows optimized for CPU-based inference environments.

---

## 2. System Overview

### 2.1 Purpose
The system is designed to:
- Train custom YOLOv8 models for insect (beetle) detection
- Provide efficient CPU-based inference capabilities
- Support automated training workflows with comprehensive logging
- Enable model deployment in resource-constrained environments

### 2.2 Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training Pipeline                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dataset â†’ Preprocessing â†’ Training â†’ Validation â†’ Export  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Inference Pipeline                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Input Images â†’ Detection â†’ Visualization â†’ Output       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Project Structure

### 3.1 Directory Organization

```
insect-detection-training/
â”œâ”€â”€ ğŸ“ Core Components
â”‚   â”œâ”€â”€ detect_insect.py               # Main detection script
â”‚   â”œâ”€â”€ train_yolo.py                  # Training script
â”‚   â”œâ”€â”€ yolov8_training_colab.ipynb   # Jupyter training notebook
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“ Configuration & Documentation
â”‚   â”œâ”€â”€ CLAUDE.md                      # Project rules and guidelines
â”‚   â”œâ”€â”€ README.md                      # Project documentation
â”‚   â”œâ”€â”€ system_specification.md       # Technical specifications
â”‚   â”œâ”€â”€ LICENSE                        # Project license
â”‚   â””â”€â”€ .gitignore                     # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“ Training Data (datasets/)
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/                    # Training images
â”‚   â”‚   â””â”€â”€ labels/                    # Training labels (YOLO format)
â”‚   â”œâ”€â”€ valid/
â”‚   â”‚   â”œâ”€â”€ images/                    # Validation images
â”‚   â”‚   â””â”€â”€ labels/                    # Validation labels
â”‚   â”œâ”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ images/                    # Test images
â”‚   â”‚   â””â”€â”€ labels/                    # Test labels
â”‚   â””â”€â”€ data.yaml                      # Dataset configuration
â”‚
â”œâ”€â”€ ğŸ“ Local Testing Environment
â”‚   â”œâ”€â”€ input_images/                  # ğŸ” Input images for detection
â”‚   â”‚   â”œâ”€â”€ 08-03.jpg                  # Sample beetle image (2.0MB)
â”‚   â”‚   â”œâ”€â”€ 20240810_130054-1600x1200-1-853x640.jpg
â”‚   â”‚   â”œâ”€â”€ 86791_ext_04_0.jpg
â”‚   â”‚   â”œâ”€â”€ insect_catching_1220x752.jpg
â”‚   â”‚   â””â”€â”€ point_thumb01.jpg
â”‚   â”‚
â”‚   â”œâ”€â”€ output_images/                 # ğŸ“¤ Detection results (PNG format)
â”‚   â”‚   â”œâ”€â”€ 08-03.png                  # Processed with bounding boxes
â”‚   â”‚   â”œâ”€â”€ 20240810_130054-1600x1200-1-853x640.png
â”‚   â”‚   â”œâ”€â”€ 86791_ext_04_0.png
â”‚   â”‚   â”œâ”€â”€ insect_catching_1220x752.png
â”‚   â”‚   â””â”€â”€ point_thumb01.png
â”‚   â”‚
â”‚   â”œâ”€â”€ weights/                       # ğŸ¤– Trained model files
â”‚   â”‚   â”œâ”€â”€ best.pt                    # Best model weights (6.3MB)
â”‚   â”‚   â”œâ”€â”€ best.onnx                  # ONNX export (12.3MB)
â”‚   â”‚   â””â”€â”€ best.hef                   # Hailo NPU format (9.3MB)
â”‚   â”‚
â”‚   â”œâ”€â”€ logs/                          # ğŸ“Š Detection logs
â”‚   â”‚   â””â”€â”€ detection_log_YYYYMMDD_HHMMSS.csv
â”‚   â”‚
â”‚   â””â”€â”€ detection_logs/                # ğŸ” Real-time inference logs
â”‚       â””â”€â”€ detection_log_YYYYMMDD_HHMMSS.txt
â”‚
â””â”€â”€ ğŸ“ Development & Build
    â”œâ”€â”€ .git/                          # Git repository
    â”œâ”€â”€ .claude/                       # Claude Code configuration
    â””â”€â”€ .mcp.json                      # MCP configuration
```

### 3.2 Directory Purposes

#### 3.2.1 Training Data (`datasets/`)
- **Size**: ~500+ beetle images across train/valid/test splits
- **Format**: YOLO format (normalized coordinates)
- **Source**: Roboflow dataset (CC BY 4.0 license)
- **Status**: Excluded from Git (.gitignore)

#### 3.2.2 Local Testing Environment
- **`input_images/`**: Place new images for detection testing
- **`output_images/`**: Receive annotated results with bounding boxes
- **`weights/`**: Store trained model files (PyTorch and ONNX)
- **`logs/`**: CSV logs with detection details and performance metrics

#### 3.2.3 Workflow Integration
1. **Training**: Use Jupyter notebook or train_yolo.py
2. **Model Export**: Save best.pt to weights/ directory
3. **Local Testing**: Place images in input_images/
4. **Detection**: Run detect_insect.py with custom models
5. **Results**: View annotated images in output_images/

---

## 4. System Components

### 4.1 Core Modules

#### 4.1.1 Training Module (`train_yolo.py`)
**Purpose**: Automated YOLOv8 model training and fine-tuning

**Key Features**:
- Pre-trained model initialization
- Custom dataset integration
- Automated training pipeline
- Real-time progress monitoring
- Model validation and metrics reporting

**Technical Specifications**:
- **Framework**: Ultralytics YOLOv8
- **Supported Models**: YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l, YOLOv8x
- **Input Format**: YOLO format annotations
- **Output Format**: PyTorch (.pt), ONNX, TorchScript

#### 4.1.2 Detection Module (`detect_insect.py`)
**Purpose**: Batch image processing and insect detection

**Key Features**:
- Multi-format image support (JPEG, PNG)
- Batch processing capabilities
- Bounding box visualization
- Performance metrics logging

#### 4.1.3 Real-time Inference Module (`hailo_beetle_detection_fixed.py`)
**Purpose**: Production-ready real-time beetle detection with Hailo 8L NPU acceleration

**Key Features**:
- **Hardware Acceleration**: Hailo 8L NPU optimized inference
- **Multi-source Input**: USB camera, RPi camera, video file support
- **Real-time Processing**: Live video stream processing with minimal latency
- **Visual Debugging**: OpenCV-based GUI with bounding box overlays
- **Comprehensive Logging**: Detailed detection analysis and performance monitoring
- **Production Deployment**: Headless operation for edge computing applications

**Technical Specifications**:
- **Target Platform**: Raspberry Pi 5 with Hailo 8L AI Kit
- **Model Format**: HEF (Hailo Executable Format)
- **Input Resolution**: 640Ã—640 RGB (NPU optimized)
- **Framework Integration**: GStreamer multimedia pipeline
- **Detection Classes**: Custom 1-class beetle detection model

---

## 5. Training System Detailed Specification

### 5.1 Training Script Architecture

#### 5.1.1 Function Overview

| Function | Purpose | Input | Output |
|----------|---------|-------|--------|
| `setup_logging()` | Initialize logging system | None | Logger instance |
| `validate_dataset()` | Verify dataset structure | Dataset path | Boolean validation result |
| `check_system_requirements()` | System compatibility check | None | System info logs |
| `train_model()` | Execute model training | Training parameters | Trained model, results |
| `validate_model()` | Model performance evaluation | Model, dataset | Validation metrics |
| `export_model()` | Model format conversion | Model, formats | Exported model files |

#### 5.1.2 Training Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--data` | str | Required | Path to dataset configuration (data.yaml) |
| `--model` | str | yolov8n.pt | Pre-trained model selection |
| `--epochs` | int | 100 | Number of training epochs |
| `--batch` | int | 16 | Training batch size |
| `--imgsz` | int | 640 | Input image size (pixels) |
| `--device` | str | auto | Hardware device (auto/cpu/gpu) |
| `--project` | str | training_results | Output directory name |
| `--name` | str | beetle_detection | Experiment identifier |
| `--export` | bool | False | Enable model export |
| `--validate` | bool | True | Enable post-training validation |

### 5.2 Training Workflow

#### 5.2.1 Initialization Phase
1. **Logging Setup**
   - Create timestamped log files in `logs/` directory
   - Configure dual output (file + console)
   - Set logging level to INFO

2. **System Validation**
   - Python version verification
   - PyTorch installation check
   - CUDA availability detection
   - GPU enumeration and specifications
   - OpenCV version confirmation

3. **Dataset Validation**
   - Verify `data.yaml` existence
   - Check directory structure integrity
   - Count files in train/valid/test splits
   - Validate image-label correspondence

#### 5.2.2 Training Phase
1. **Model Initialization**
   - Load pre-trained YOLOv8 weights
   - Configure model architecture
   - Set training hyperparameters

2. **Training Execution**
   - Batch data loading and augmentation
   - Forward/backward propagation
   - Loss calculation and optimization
   - Checkpoint saving (every 10 epochs)
   - Validation set evaluation

3. **Progress Monitoring**
   - Real-time loss tracking
   - Validation metrics computation
   - Training time measurement
   - Resource utilization logging

#### 5.2.3 Validation Phase
1. **Performance Metrics**
   - mAP@0.5 (Mean Average Precision at IoU 0.5)
   - mAP@0.5:0.95 (Mean Average Precision across IoU thresholds)
   - Precision (True Positives / (True Positives + False Positives))
   - Recall (True Positives / (True Positives + False Negatives))

2. **Output Generation**
   - Confusion matrix visualization
   - Training/validation curves
   - Sample detection visualizations
   - Model performance summary

#### 5.2.4 Export Phase
1. **Format Conversion**
   - ONNX export for cross-platform deployment
   - TorchScript export for production optimization
   - Model weight extraction

2. **File Organization**
   - Best model weights (`best.pt`)
   - Latest checkpoint (`last.pt`)
   - Training configuration backup
   - Results visualization files

---

## 6. Dataset Specifications

### 6.1 Dataset Structure
```
datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/          # 400 training images
â”‚   â””â”€â”€ labels/          # 400 YOLO format labels
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ images/          # 50 validation images
â”‚   â””â”€â”€ labels/          # 50 YOLO format labels
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/          # 50 test images
â”‚   â””â”€â”€ labels/          # 50 test labels
â””â”€â”€ data.yaml            # Dataset configuration
```

### 6.2 Data Format Requirements

#### 6.2.1 Image Specifications
- **Formats**: JPEG, PNG
- **Resolution**: Minimum 640x640 pixels recommended
- **Color Space**: RGB
- **File Naming**: Consistent with corresponding label files

#### 6.2.2 Label Format (YOLO)
```
class_id x_center y_center width height
```
- **class_id**: Integer (0 for 'beetle')
- **Coordinates**: Normalized (0.0 to 1.0)
- **File Extension**: `.txt`

#### 6.2.3 Configuration File (data.yaml)
```yaml
train: ./train/images
val: ./valid/images
test: ./test/images

nc: 1
names: ['beetle']

roboflow:
  workspace: z-algae-bilby
  project: beetle
  version: 1
  license: CC BY 4.0
  url: https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1
```

---

## 8. System Requirements

### 8.1 Hardware Requirements

#### 8.1.1 Minimum Requirements
- **CPU**: Quad-core processor (Intel i5 or AMD Ryzen 5 equivalent)
- **RAM**: 8GB system memory
- **Storage**: 10GB free space for datasets and models
- **GPU**: Optional (CUDA-compatible for accelerated training)

#### 8.1.2 Recommended Requirements
- **CPU**: 8-core processor (Intel i7 or AMD Ryzen 7)
- **RAM**: 16GB+ system memory
- **Storage**: 50GB+ SSD storage
- **GPU**: NVIDIA GPU with 6GB+ VRAM (RTX 3060 or better)

### 8.2 Software Requirements

#### 8.2.1 Operating System
- **Primary**: Ubuntu 22.04 LTS (WSL2 on Windows 10/11)
- **Alternative**: macOS 12+, Windows 10/11 with WSL2
- **Python**: 3.9+ (tested with 3.10.12)

#### 8.2.2 Dependencies (Verified Versions)
```
# Core ML Frameworks
torch==2.7.1                    # Deep Learning Framework
torchvision==0.22.1             # Computer Vision
ultralytics==8.3.162            # YOLOv8 Implementation

# Computer Vision & Image Processing
opencv-python==4.11.0.86        # Computer Vision Library
numpy==2.2.6                    # Numerical Computing
pandas==2.3.0                   # Data Analysis
matplotlib==3.10.3              # Plotting & Visualization
pillow>=11.3.0                  # Image Processing

# Additional Dependencies
ultralytics-thop==2.0.14        # Model Profiling
pyyaml>=5.3.1                   # Configuration Files
tqdm>=4.65.0                    # Progress Bars
```

#### 8.2.3 Installation Commands
```bash
# Install core dependencies
pip3 install torch torchvision ultralytics opencv-python

# Or install all requirements
pip3 install -r requirements.txt
```

#### 8.2.4 Current Environment Status
- **System**: Linux WSL2 (Ubuntu) x86_64
- **Python**: 3.10.12 (System Level)
- **Package Installation**: User-level (~/.local/lib/python3.10/site-packages/)
- **Last Verified**: 2025-07-04

---

## 9. Performance Specifications

### 9.1 Training Performance

#### 9.1.1 Target Metrics
- **Training Time**: â‰¤ 2 hours for 100 epochs (GPU environment)
- **Memory Usage**: â‰¤ 8GB RAM during training
- **Model Convergence**: Loss stabilization within 50-80 epochs
- **Validation mAP@0.5**: â‰¥ 0.7 for beetle detection

#### 9.1.2 Achieved Performance (2025-07-04)
**ğŸ† Exceptional Results Achieved:**
- **Final mAP@0.5**: 0.9763 (97.63%) - **39.4% above target**
- **mAP@0.5:0.95**: 0.6550 (65.50%)
- **Precision**: 0.9598 (95.98%)
- **Recall**: 0.9305 (93.05%)
- **Training Platform**: Google Colab (GPU accelerated)
- **Model Size**: YOLOv8 Nano (best.pt: 6.3MB)
- **Training Status**: Production-ready quality

#### 9.1.3 Hardware-Specific Performance
| Configuration | Training Time (100 epochs) | Memory Usage | Batch Size |
|---------------|----------------------------|--------------|------------|
| CPU Only | 8-12 hours | 4-6 GB | 8-16 |
| RTX 3060 | 1-2 hours | 6-8 GB | 32-64 |
| RTX 4080 | 30-60 minutes | 8-12 GB | 64-128 |

### 9.2 Inference Performance

#### 9.2.1 Target Specifications
- **Processing Time**: â‰¤ 1,000ms per image (CPU inference)
- **Memory Efficiency**: â‰¤ 2GB RAM during inference
- **Accuracy Targets**:
  - True Positive Rate: â‰¥ 85%
  - False Positive Rate: â‰¤ 5%
  - Precision: â‰¥ 0.8
  - Recall: â‰¥ 0.8

#### 9.2.2 Achieved Local Inference Performance (2025-07-04)
**ğŸš€ Outstanding Local Performance:**
- **Average Processing Time**: Standard CPU processing time
- **Processing Range**: Variable processing time per image
- **Test Results**: 5/5 images processed successfully (100% success rate)
- **Total Detections**: 9 beetles detected across 5 images
- **System**: Linux WSL2, Python 3.10.12, CPU-only inference
- **Model**: best.pt (6.3MB YOLOv8 Nano)
- **Memory Usage**: Minimal system impact

#### 9.2.3 Real-time Inference Modes (2025-07-13)

**Production NPU Inference (`hailo_beetle_detection_fixed.py`)**
- **Target Hardware**: Raspberry Pi 5 + Hailo 8L NPU (AI Kit)
- **Model Format**: HEF (Hailo Executable Format) - best.hef (9.3MB)
- **Input Sources**:
  - USB Camera (`--input usb --device /dev/video0`)
  - Raspberry Pi Camera (`--input rpi`)
  - Video Files (`--input /path/to/video.mp4`)
- **Processing Resolution**: 640Ã—640 RGB (optimized for Hailo NPU)
- **Real-time Capability**: Frame-by-frame processing with hardware acceleration

**Operating Modes:**
1. **Headless Mode (Default)**
   ```bash
   python3 hailo_beetle_detection_fixed.py --device /dev/video0
   ```
   - Console-only output with detection statistics
   - Minimal resource usage for production deployment
   - Continuous operation without GUI overhead

2. **Visual Debug Mode**
   ```bash
   python3 hailo_beetle_detection_fixed.py --device /dev/video0 --display
   ```
   - Real-time GUI window with live video feed
   - Bounding box visualization overlays
   - Interactive detection confidence display
   - ESC key termination support

3. **Comprehensive Logging Mode**
   ```bash
   python3 hailo_beetle_detection_fixed.py --device /dev/video0 --verbose
   ```
   - Timestamped log files in `detection_logs/` directory
   - Frame-by-frame detection analysis
   - Bounding box coordinate logging
   - Session statistics and performance metrics

**Logging System Features:**
- **Automatic Log Creation**: `detection_log_YYYYMMDD_HHMMSS.txt`
- **Detailed Detection Records**: All detected objects with confidence scores
- **Coordinate Tracking**: Normalized bounding box coordinates (xmin, ymin, xmax, ymax)
- **Performance Analytics**: Frame processing rates, total detections, session duration
- **Debug Information**: Pipeline status, callback execution, error tracking

**Technical Implementation:**
- **GStreamer Pipeline**: Optimized multimedia framework integration
- **OpenCV Integration**: Real-time frame processing and visualization
- **Hailo API**: Direct NPU inference with custom 1-class beetle model
- **Multi-threading**: Concurrent video processing and display rendering

---

## 10. Output Specifications

### 10.1 Training Outputs

#### 10.1.1 Model Files
- **best.pt**: Best performing model weights (locally stored)
- **last.pt**: Final epoch weights (locally stored)
- **Model exports**: ONNX, TorchScript formats

#### 10.1.2 Model Distribution
- **Public Repository**: https://huggingface.co/Murasan/beetle-detection-yolov8
- **License**: AGPL-3.0 (inherited from YOLOv8)
- **Available Formats**: 
  - PyTorch format (best.pt, 6.26MB)
  - ONNX format (best.onnx, 12.3MB)
- **Performance Metrics**: mAP@0.5: 97.63%, mAP@0.5:0.95: 89.56%

#### 10.1.3 Visualization Files
- **results.png**: Training/validation curves
- **confusion_matrix.png**: Classification performance matrix
- **labels.jpg**: Ground truth label distribution
- **predictions.jpg**: Model prediction samples

#### 10.1.4 Log Files
- **Training logs**: Timestamped training progress
- **CSV metrics**: Epoch-by-epoch performance data
- **System logs**: Hardware utilization and errors

### 10.2 File Organization
```
training_results/
â””â”€â”€ beetle_detection/
    â”œâ”€â”€ weights/
    â”‚   â”œâ”€â”€ best.pt
    â”‚   â””â”€â”€ last.pt
    â”œâ”€â”€ plots/
    â”‚   â”œâ”€â”€ results.png
    â”‚   â”œâ”€â”€ confusion_matrix.png
    â”‚   â””â”€â”€ predictions.jpg
    â””â”€â”€ logs/
        â””â”€â”€ training_YYYYMMDD_HHMMSS.log
```

---

## 11. Error Handling and Logging

### 11.1 Error Classification

#### 11.1.1 Critical Errors
- Dataset validation failures
- Model loading errors
- CUDA out-of-memory errors
- File system permission issues

#### 11.1.2 Warning Conditions
- Low available memory
- Slow training convergence
- Missing optional dependencies
- Suboptimal hardware configuration

### 11.2 Logging Specifications

#### 11.2.1 Log Levels
- **INFO**: Normal operation progress
- **WARNING**: Non-critical issues
- **ERROR**: Recoverable failures
- **CRITICAL**: System-stopping errors

#### 11.2.2 Log Format
```
YYYY-MM-DD HH:MM:SS - LEVEL - MESSAGE
```

#### 11.2.3 Log Rotation
- New log file per training session
- Timestamp-based naming convention
- Automatic cleanup of old logs (>30 days)

---

## 12. Security Considerations

### 12.1 Data Security
- Dataset files excluded from version control
- No sensitive information in configuration files
- Secure handling of model weights

### 12.2 System Security
- Input validation for all user parameters
- Safe file path handling
- Memory usage monitoring and limits

---

## 13. Deployment Guidelines

### 13.1 Development Environment Setup
1. Clone repository from GitHub
2. Create Python virtual environment
3. Install dependencies from requirements.txt
4. Download and prepare dataset
5. Verify system requirements

### 13.2 Training Execution
```bash
# Basic training command
python train_yolo.py --data datasets/data.yaml --epochs 100

# Production training with custom parameters
python train_yolo.py \
    --data datasets/data.yaml \
    --model yolov8s.pt \
    --epochs 200 \
    --batch 32 \
    --imgsz 640 \
    --device 0 \
    --export
```

### 13.3 Model Deployment
1. Export trained model to ONNX format
2. Optimize for target hardware platform
3. Integrate with inference application
4. Validate performance on test dataset

---

## 14. Maintenance and Updates

### 14.1 Model Retraining
- Recommended frequency: Monthly with new data
- Version control for model weights
- Performance comparison with previous versions

### 14.2 System Updates
- Regular dependency updates
- YOLOv8 framework version monitoring
- Security patch application

---

## 15. Testing and Validation

### 15.1 Unit Testing
- Dataset validation functions
- Model loading/saving operations
- Configuration file parsing
- Error handling mechanisms

### 15.2 Integration Testing
- End-to-end training pipeline
- Model export functionality
- Cross-platform compatibility
- Performance benchmarking

### 15.3 Acceptance Testing
- Model accuracy validation
- Performance requirement verification
- User interface testing
- Documentation completeness

---

## 16. Appendices

### 16.1 Command Reference
```bash
# Display help information
python train_yolo.py --help

# Quick training with minimal parameters
python train_yolo.py --data datasets/data.yaml --epochs 50

# High-quality training with export
python train_yolo.py --data datasets/data.yaml --model yolov8m.pt --epochs 200 --export

# CPU-only training
python train_yolo.py --data datasets/data.yaml --device cpu --batch 8
```

### 16.2 Troubleshooting Guide

#### 16.2.1 Common Issues
- **"Dataset not found"**: Verify dataset directory structure
- **"CUDA out of memory"**: Reduce batch size or use CPU
- **"Permission denied"**: Check file system permissions
- **"Import error"**: Reinstall dependencies

#### 16.2.2 Performance Optimization
- Use SSD storage for faster data loading
- Optimize batch size based on available memory
- Enable mixed precision training for GPU speedup
- Close unnecessary applications during training

---

*Document Version: 1.1*  
*Last Updated: 2025-07-13*  
*Contact: Development Team*

---

## 17. Real-time Inference System Updates (2025-07-13)

### 17.1 Enhanced Inference Capabilities

The system has been significantly enhanced with comprehensive real-time inference capabilities specifically designed for Raspberry Pi 5 + Hailo 8L NPU deployment. These updates provide production-ready beetle detection with advanced debugging and visualization features.

### 17.2 New System Components

#### 17.2.1 Production Inference Script
- **File**: `hailo_beetle_detection_fixed.py`
- **Purpose**: Production-ready real-time beetle detection with NPU acceleration
- **Dependencies**: GStreamer, OpenCV, Hailo SDK, Python logging

#### 17.2.2 Troubleshooting Documentation
- **File**: `RASPBERRY_PI_HAILO_TROUBLESHOOTING.md`
- **Purpose**: Comprehensive debugging guide for Raspberry Pi deployment
- **Content**: Step-by-step solutions for common GStreamer and NPU issues

#### 17.2.3 Testing Utilities
- **Files**: `test_simple_pipeline.py`, `test_original_pipeline.py`
- **Purpose**: Pipeline validation and debugging tools
- **Functionality**: Isolated testing of GStreamer pipeline components

### 17.3 Deployment Architecture

```
Real-time Inference Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Video Input Sources                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  USB Camera â”€â”€â”                                                     â”‚
â”‚  RPi Camera â”€â”€â”¼â”€â”€ GStreamer Pipeline â”€â”€ Hailo 8L NPU â”€â”€ Detection  â”‚
â”‚  Video File â”€â”€â”˜                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Output Processing                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Console Logs â”€â”€â”                                                   â”‚
â”‚  GUI Display â”€â”€â”€â”¼â”€â”€ Real-time Feedback                             â”‚
â”‚  Log Files   â”€â”€â”€â”˜                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 17.4 Operating Mode Specifications

#### 17.4.1 Mode Comparison Table

| Feature | Headless Mode | Visual Debug Mode | Logging Mode |
|---------|---------------|-------------------|--------------|
| **Command** | `--device /dev/video0` | `--display` | `--verbose` |
| **CPU Usage** | Minimal | Moderate | Minimal |
| **Memory Usage** | Low | Medium | Low |
| **Output** | Console only | GUI + Console | Files + Console |
| **Use Case** | Production | Development | Analysis |
| **Network Required** | No | No | No |
| **Storage Impact** | None | None | Log files |

#### 17.4.2 Performance Characteristics

| Metric | Headless | Visual Debug | Logging |
|--------|----------|--------------|---------|
| **Startup Time** | ~2-3 seconds | ~3-5 seconds | ~2-3 seconds |
| **Frame Processing** | Real-time | Real-time | Real-time |
| **Detection Latency** | <100ms | <150ms | <100ms |
| **Resource Overhead** | Minimal | +20-30% | +5-10% |

### 17.5 Integration Guidelines

#### 17.5.1 Development Workflow
1. **Initial Testing**: Use visual debug mode for verification
2. **Performance Analysis**: Enable comprehensive logging
3. **Production Deployment**: Switch to headless mode
4. **Maintenance**: Use logging mode for ongoing monitoring

#### 17.5.2 Quality Assurance
- **Automated Testing**: Pipeline validation with test utilities
- **Performance Monitoring**: Log analysis for optimization
- **Error Handling**: Comprehensive exception management
- **Documentation**: Complete troubleshooting guide for common issues